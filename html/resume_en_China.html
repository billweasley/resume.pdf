<!DOCTYPE HTML>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <style type="text/css" media="all">
    body {
  font: 13px/1.3 Verdana Helvetica, arial, freesans, clean, sans-serif;
  color: #333;
  background-color: #fff;
}

a {
  text-decoration: none;
  color: black;
}

/* Headlines has different font sizes */
h1 {
  font-size: 1.6em;
}

h2 {
  font-size: 1.1em;
}

/* H1 and H2 has underline */
h2 {
  border-bottom: 1px solid #999;
  font-weight: bold;
}
h1 {
	font-weight: bold;
}

/* ul & li */
ul {
  list-style-type: disc;
  margin-left: -0.4em;
  margin-top: 0.4em;
  padding-left: 3em;
  padding-right: 3em;
}

li {
  display: list-item;
}

/* school logo */
img[alt="school-logo"] {
  position: absolute;
  top: .3em;
  right: .8em;
  height: 1.7em;
  background-color: #fff;
}

/* avatar */
img[alt="avatar"] {
  position: absolute;
  top: 3.8em;
  right: 1em;
  height: 8.5em;
  background-color: #fff;
}


/* strong fonts as little title */
/* ---- only for those ugly lists !--- */

li em {
  font-size: .8em;
  color: #777;
  font-style: italic;
  display: flex;
}

datetime {
  width: 10em;
  float: left;
}

head_title {
    text-decoration: underline;
    text-decoration-color: #ddd;
    text-decoration-thickness: 1px;
    font-weight: bold;
}
head_ {
  margin-left: 0.5em;
  display: flex;
}

lang {
  float: right;
  font-size: .8em;
  border-bottom: 1px dotted #ddd;
}
to_right{
 float: right;
}
to_left{
 float: left;
}
description_nleft {
  margin-top: 1em; /* away from big title, looks like a block*/
  font: 13px/1.3 Verdana Helvetica, arial, freesans, clean, sans-serif;
}
description {
  margin-top: 1em; /* away from big title, looks like a block*/
  display: block;
  text-align:justify;
}
techstack{
  margin-top: .5em; /* away from big title, looks like a block*/
  display: block;
  text-align:justify;
  margin-bottom:.5em;
}
adjestl{
  margin-left: 5em; 
}
desline {
  margin-left: 15em;
}

hireable {
  font-size: 1em;
  color: #777;
}

footnote {
  position: absolute;
  bottom: 0;
  display: block;
  font-size: .8em;
  color: #777;
}

small {
  font-size: .9em;
}
  </style>
</head>
<body>
  <h1><to_left>Hao-xuan (Horace) Wang</to_left>  <description_nleft><to_right><a href="tel://008618622468042"> +86 18622468042</a></to_right><br> <to_right><a href="billweasley20092@gmail.com">billweasley20092@gmail.com</a> </to_right><br><to_right><b>Github: </b> <a href="https://github.com/billweasley">https://github.com/billweasley</a></to_right><br><to_right><b>Linkedin: </b> <a href="https://www.linkedin.com/in/horace-haoxuan-wang">https://www.linkedin.com/in/horace-haoxuan-wang</a></to_right><br><to_right><b>Personal Website: </b> <a href="http://shellcottage.me">http://shellcottage.me</a></to_right></description_nleft></h1>

<h2>Work Experience</h2>

<ul>
<li><p><datetime>2022.03 - Now </datetime> <head_><head_title> Machine Learning Engineer, ASR and Language Tech </head_title> @ Zoom </head_>
<description><small>
Tech stack: Torch/Pytorch, ONNX, Kubernates, Huggingface
<ul>
<li> Implement and train speech recognition and text punctuation models, worked on Danish language from 0 to 1. Initial WER on test dataset was about <b>8%</b>, and phonic data argument reduces the WER further, which <b>outperforms the MS Team&#39;s result</b>. Initial casing and punctuation overall F1 is around <b>70%</b>. </li>
<li> Implement, test, maintain, and evaluate key features of the inference system, including <b>decoding</b>, <b>multi-head attention (MHA) timestamp generation</b>, and <b>post-processing</b> code. </li>
<li> Write a meta-prompt, and then use a open-source Large Language Model (LLM) (e.g. Mistral MoE 8x7B) to generate hundreds of dialogue scenario prompts, and combine these prompts with different reading formats of digital sequences also generated by the LLM. Pass the text to colleagues to generate audio using internal/Microsoft TTS services, thereby obtaining a test set and a training dataset. After fine-tuning the production model with the training dataset, there is a slight improvement on another internal digital test dataset (Absolute digital WER: -0.4%). </li>
<li> (Ongoing) Conduct internal evaluation for the ASR capabilities of large audio models, such as Qwen Audio, Whisper.</li>
<li> Independently completed the implementation, optimization, and performance evaluation (WER, RTF/latency/throughput) of Whisper inference support, using in-house VAD (Voice Activity Detection) model and the open-source WhisperX. Achieved higher throughput compared to the official implementation and lower WER on most test sets. </li>
<li> Implement the multi-head attention (MHA) based time alignment over LAS/seq2seq model so providing a good word level timestamp for multilingual transcription for fulfilling business requirements. [A U.S. patent has been filed for this]</li>
<li> Cooperate with the downstream web and infrastructure team to simplify the offline transcription system architecture and deployment to support <b>35+ single-language</b> models for <b>5+</b> different downstream services in <b>10+ different regions around the world</b>. </li>
<li> Build a systmatic model management practice from scratch to support complex combination in response to the business and languages requirements. </li>
<li> Evaluate the performance of the speech recognition system, and find the most suitable parameters to reduce real-time factor, or improve the throughput of the system. </li>
<li> Watch closely on online bugs reported from customers, and fix them either from code, or from data quality side.</li>
<li> Cooperate with hardware manufacturers (such as Nvidia) to evaluate the inference performance of proprietary inference systems in order to reduce the resource costs of inference. </li>
<li> Some cutting-edge explorations that are being done and planned to be done: e.g. LLM re-score/generative error correction etc. </li>
</ul>
</small></description></p></li>
<li><p><datetime>2020.09 - 2021.12 </datetime> <head_><head_title> Data Scientist </head_title> @ Barclays </head_>
<description><small>
Tech stack: Spark / PySpark, Amazon Deep Java Library (DJL), Tensorflow / Keras, Pandas, Jupyter, Pretrained Transformers / Likelihood Ratio<br>
<ul>
<li>
Company address matching and entity matching without internal GPU and labeled data available. Solve using an active learning method. Start from constructing some small datasets only with external data and training an XGBoost tree, then label samples in the boundary and fine-turn BERT models in an iterative way. Finish the inference on 6 million internal pair-wised samples with this model on a CPU cluster, using a DJL based pipeline built from scratch on my own. It achieved a very satisfying result of <b>94% F1 score on a noisy testing dataset from 89% where we started</b>. The model does inference offline on our Spark cluster in a distributed way. For 6 million pair-wised samples, the running time is under 1 hour (on a cluster with 80 CPUs).
</li>
<li>
Predict the aggregated user&#39;s transaction activity (volume and value) using the historical mean and Informer model, a variant of Transformer for time-series modeling. Following that, a counterfactual was constructed to provide an evaluation of how much finance loss that the bank suffers from system downtime and to find out the critical period for the system reliability.
</li>
<li>
Maintain the Spark cluster for the team, and build up pipelines for distributed inference by combining DJL / PySpark UDF with models.Collaborated with one of my colleagues, we created a team-wised package to start a Spark session within 4 lines of codes, which significantly reduces the overhead of using Spark for colleagues who are not with a distributed computing background.
</li>
</ul>
</small></description></p></li>
<li><p><datetime>2019.08 - 2020.09</datetime> <head_><head_title>Java Backend Developer </head_title> @ Barclays </head_> </p></li>
</ul>

<h2>Education</h2>

<ul style="list-style-type: none;">
<li><head_><datetime>2018 - 2019</datetime> MSc Web Science and Big Data Analytics  @&nbsp;<b>University College London, </b>&nbsp;Distinction</head_></li>
<li><head_><datetime>2016 - 2018</datetime> BSc Internet Computing  @&nbsp;<b>University of Liverpool *, </b>&nbsp; First class</head_></li>
<li><head_><datetime>2014 - 2016</datetime> BSc Information and Computing Science  @&nbsp;<b>Xi'an Jiaotong-Liverpool University * </b>&nbsp;</head_>
<li><description><small><b>*Note: </b>2+2 pathway routine (first 2 years in Suzhou, China and final 2 years in Liverpool, UK), dual degree.</small></description></li>
</li>
</ul>

<h2>Personal Project</h2>

<ul>
<li><head_><datetime>2024.06 - </datetime> <head_title>Fine-tuning and evaluation of medical record data on Large Language Models (LLMs) </head_title> </head_>
<description>
<small>
(Ongoing) Using hundreds of thousands of de-identified medical record, we are conducting full fine-tuning and (Q)LoRA fine-tuning on different Large Language Model (LLM) foundation models for tasks such as department classification, medical record summarization, and discharge certification, and evaluating their effectiveness. We plan to open-source the data in the future.
</small>
</description></li>
</ul>

<h2>Technical Article</h2>

<ul>
<li><head_><head_title>&quot;Accelerating Deep Learning on the JVM with Apache Spark and NVIDIA GPUs&quot; </head_title> </head_>
<description><small>
Author: Haoxuan Wang, Qin Lan [AWS], Carol McDonald [Nvidia];  Link: <a href="https://www.infoq.com/articles/deep-learning-apache-spark-nvidia-gpu/?itm_source=articles_about_ai-ml-data-eng&amp;itm_medium=link&amp;itm_campaign=ai-ml-data-eng">https://www.infoq.com/articles/deep-learning-apache-spark-nvidia-gpu/?itm_source=articles_about_ai-ml-data-eng&amp;itm_medium=link&amp;itm_campaign=ai-ml-data-eng</a>
</small>
</description></li>
</ul>

<h2>Early Stage Project</h2>

<ul>
<li><head_><datetime>2019.06 - 2019.09</datetime> <head_title>Project Internship (Master Degree Thesis) </head_title>  @ Astroscreen </head_>
<description>
<small>
Social media posting language source identification (tweets and gabs) project.
Finished a crawler for collecting language (posts) data from Gab.com, pre-processed data using Regular Expression, built models for classifying the source of these data by fine-turning BERT and XLNet,
visualized results using t-SNE, did &quot;leave-one-hashtag-out&quot; cross-validation, and evaluated models using some common matrics (Accuracy, F1 score, Confusion Matrix, Matthews Correlation Coefficient). After fine-turning, XLNet shows a 86% F1 score on hashtag-balanced test dataset, reducing from 97% on random-balanced test dataset. The results show the protential for doing source checking using a model and also indicate the importance for avoiding data leakage.
</small>
</description></li>
</ul>

</body>
</html>