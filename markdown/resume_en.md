# <to_left>Hao-xuan (Horace) Wang</to_left>  <description_nleft><to_right>[ +44 (0)7774857427](tel://00447774857427)</to_right><br> <to_right>[billweasley20092@gmail.com](billweasley20092@gmail.com) </to_right><br><to_right><b>Github: </b> [https://github.com/billweasley](https://github.com/billweasley)</to_right><br><to_right><b>Linkedin: </b> [https://www.linkedin.com/in/horace-haoxuan-wang](https://www.linkedin.com/in/horace-haoxuan-wang)</to_right></description_nleft>    

Work Experience
--------
- <datetime>2020.08 -  </datetime> <head_><head_title>Barclays UK</head_title>, Graduate Data Scientist, Data Scientist Team (2nd rotation)</head_>

- <datetime>2019.08 - 2020.07</datetime> <head_><head_title>Barclays UK</head_title>, Graduate Backend Developer, Card Platform Team (1st rotation)</head_> 
<description><small>
Tech stack: Jenkins, Jira, Confluence, BitBucket, Openshift, Docker, GridGain, Maven, Gradle, Wiremock, Mockito, Spring Boot, AWS, SonarQube, Karate, AppDynamics  
<ul>
<li>End-to-end function development, testing (unit, functional, performance), deployment (CD)  </li>
<li>Add cache layer to the existing APIs to reduce the latency for repetitive data access  </li>
<li>Migrate legacy codes to internal Spring Boot templates, with refactors to enhance code readability and performance  </li>
<li>Build up handy internal tools (e.g. git hooks) and scripts (python / bash) from scratch to automate software development processes</li>
<li>Take some NLP side projects (e.g. Address NER using BERT), and trace the state-of-the-art progress in NLP area, especially in the topic of transfer learning, model compression (for low resource inference) and multi-modality fusion </li>
<li>Keep a good communication and delivery efficiency during COVID-19 pandemic, when the team has to work from home for months</li>
</ul>
</small></description>

Education
--------
- <datetime>2018 - 2019</datetime> <head_><head_title>University College London</head_title>, MSc Web Science and Big Data Analytics, Distinction</head_>
    <description><small>Core subjects: Probability Graphical Models; Introduction to Deep Learning; Complex Network; Affective Computing; Statistical NLP; Information Retrieval; Multi-agent AI, Applied Machine Learning</small></description>

- <datetime>2016 - 2018</datetime> <head_><head_title>University of Liverpool</head_title>, BSc Internet Computing, First class</head_>
    <description><small>Core subjects: Software Engineering; Database Concepts; Internet Principles (Introduce to OSI layers); Object-Oriented Programming; Distributed Systems Concepts; Software Development Tools (Mainly about testing); Principles of C && Memory Management; iOS Programming (Swift); Knowledge Representation & Reasoning; E-commerce (Auction and Security [RSA, Diffie–Hellman key exchange, Elliptic Curve Encryption]);
  </small></description>

- <datetime>2014 - 2016</datetime> <head_><head_title>Xi'an Jiaotong-Liverpool University</head_title>, BSc Information and Computing Science</head_>
  <description><small>2+2 pathway routine (first 2 years in Suzhou, China and final 2 years in Liverpool, UK), dual degree.</small></description>
  <description><small>Core subjects: Computer Systems; Introduction to Databases; Introduction to Programming in Java; Algorithmic Foundations and Problem Solving; Data Structures; Operating Systems Concepts; Human-Centric Computing; Calculus; Introduce to Discrete Mathematics  
  </small></description>
  
Projects
--------
- <datetime>2019.06 - 2019.09</datetime> <head_><head_title>Project Internship (Master Degree Thesis) @ Astroscreen</head_title> </head_>
<techstack>
<small>
Tech stack: Python, Keras, Tensorflow, MulticoreTSNE, Matlabplot
</small>
</techstack>
<description>
<small>
Social media posting language source identification (tweets and gabs) project.
Finished a crawler for collecting language (posts) data from Gab.com, pre-processed data using Regular Expression, built models for classifying the source of these data by fine-turning BERT and XLNet,
visualised results using t-SNE, did "leave-one-hashtag-out" cross-validation and evaluated models using some common matrics (Accuracy, F1 score, Confusion Matrix, Matthews Correlation Coefficient).
</small>
</description>

- <datetime>2019.03 - 2019.04</datetime> <head_><head_title>Information Retrieval Course Project</head_title> </head_>
<description><small>
Multiple practices using Fact Extraction and Verification (FEVER) dataset 
Including word counting and verification of zip's law; implementation of vector space information retrieval (TF-IDF); implementation of query likelihood document retrieve (applying Laplace Smoothing，Jelinek-Mercer Smoothing and Dirichlet Smoothing, respectively); implementation logistic regression to predict sentence relevance; implementation of Precious, Recall and F score function; using neural networks to predict document truthness.
</small>
</description>

- <datetime>2019.02 - 2019.03</datetime> <head_><head_title>Integrating BERT and Embeddings into CommonsenseQA Chanllenge</head_title> </head_>
<description><small>
We fine-turned Google BERT to CommonsenseQA challenge 1.0 (with 3 options of each question) and then integrated Conceptnet Numberbatch and ELMo embeddings attempting to improve the model performance. The challenge involves a set of MCQ questions requiring human commonsense knowledge.
We achieved 68.79% of accuracy on validation set using BERT + ELMo (soly BERT : 67.47%; BERT + Numberbatch: 67.68%).
</small>
</description>

- <datetime>2019.02 - 2019.02</datetime> <head_><head_title>"Recogising food-stimalated emotions" experimental labelling platform</head_title> </head_>
<techstack>
<small>
Tech stack: Bootstrap, JQuery, Recordrtc.js, Java, Play! framework 2, PostgreSQL, Cloud Foundry
</small>
</techstack>
<description><small>
A simple web app that we used to collect experimental data (food taste affection).  An online demo could be visited at https://affective-computing-data-collection-dist.cfapps.io/sessions （Offine now, because out of charge）.
I finished this on my own on a weekend. This is a draft version of it (we then removed the personal info and produced a local version of it).</small>
</description>

- <datetime>2019.02 - 2019.03</datetime> <head_><head_title>Maximise number of clicks through AD CTR prediction and bidding functions selection</head_title> </head_>
<techstack>
<small>
Tech stack: Python, Keras, XGBoost, Numpy, Pandas, Matlabplot    
</small>
</techstack>
<description><small>
Predicting whether a user would click the online AD (advertisement) on an AD real-time DSP bidding history dataset. The prediction results then were inputted to a bidding strategy function to predict a bid price. The total pay price is bounded by a constant total number. The dataset is unbalanced with only about 3000 positive samples (clicks) among more than 300000 bidding records. We tried many different models (XGBoosting, Shallow NN, Logistic Regression) and some bidding strategies. We also applied downsampling and re-calibration techniques in the project. We did a competition in a leaderboard with other students (30 groups) and ranked in the 3rd place (with 185 clicks and the first 2 are with 186 clicks). </small>
</description>

- <datetime>2018.12 - 2019.01</datetime> <head_><head_title>Is a uploader with more uploaded videos also more popular? A network based analysis on bilibili</head_title> </head_>
<techstack>
<small>
Tech stack: Python, networkx, graph-tool, MySQL  
</small>
</techstack>
<description><small>
Bilibili is one of the largest Chinese video-sharing websites.  The project aims to examine some properties (degree distribution and assortative coefficient) of the user (uploader) following relation network and then attempts to check if they are related
between the number of archives (that reflecting how the user active is) and the in-coming degree of the nodes (that reflecting how popular the user is) through visualisation of the network. A crawler was written in the project to acquire data from Bilibili's RESTful API.</small>
</description>

- <datetime>2017.09 - 2018.05</datetime> <head_><head_title>Simulation, Visualization and Experimental Analysis for Population Protocols and Network Constructor in 2-Dimension</head_title></head_>
<techstack>
<small>
Tech stack: Kotlin, GraphStream 
</small>
</techstack>
<description><small>
Population protocol is a theoretical model for distributed computation. The model contains a collection of indistinguishable agents.  The network constructor and the terminating grid network constructor are some models extending population protocol but with a different aim to construct networks in different topologies.  </small>
</description>